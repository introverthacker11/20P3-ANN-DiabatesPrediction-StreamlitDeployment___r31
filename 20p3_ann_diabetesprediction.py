# -*- coding: utf-8 -*-
"""20P3-ANN-DiabetesPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1655yhiX0Z9UWp7qy_9LkHEoKqBFeJDDo
"""

import pandas as pd

df = pd.read_csv('diabetes.csv')
df

df.tail(3)

df.info()

df.describe()

df.isnull().sum()

x = df.drop(['Outcome'], axis = 1)
y = df['Outcome']

x

y

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)

x_train.shape, x_test.shape, y_train.shape, y_test.shape

import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout

input_shape = x_train.shape[1:]
input_shape

model = Sequential()
model.add(Dense(activation = 'relu', units = 9, input_dim = input_shape[0], kernel_initializer = 'uniform'))
model.add(Dense(activation = 'relu', units = 9, kernel_initializer = 'uniform'))
model.add(Dense(activation = 'sigmoid', units = 1, kernel_initializer = 'uniform'))

model.summary()

model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])
history = model.fit(x_train, y_train, batch_size = 7, epochs = 20, validation_split = 0.2)

pred = model.predict(x_test)
pred = (pred > 0.5).astype("int32")
pred[0:10]

from sklearn.metrics import classification_report, confusion_matrix

print(classification_report(y_test, pred.round()))

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
x = scaler.fit_transform(x)

x_test, x_train, y_test, y_train = train_test_split(x, y, test_size = 0.2, random_state = 0, stratify = y)

len(df[df['Outcome'] == 0]), len(df[df['Outcome'] == 1])

print("Train set:")
print("0s:", len(y_train[y_train == 0]))
print("1s:", len(y_train[y_train == 1]))

print("\nTest set:")
print("0s:", len(y_test[y_test == 0]))
print("1s:", len(y_test[y_test == 1]))

import numpy as np

def count_classes(y, name):
    unique, counts = np.unique(y, return_counts=True)
    print(f"{name} counts:", dict(zip(unique, counts)))
    print(f"{name} percentages:", dict(zip(unique, counts / len(y) * 100)))

count_classes(y_train, "Train")
count_classes(y_test, "Test")

model = Sequential()
model.add(Dense(activation = 'relu', units = 120, input_dim = input_shape[0], kernel_initializer = 'uniform'))
model.add(Dense(activation = 'relu', units = 120, kernel_initializer = 'uniform'))
model.add(Dense(activation = 'sigmoid', units = 1, kernel_initializer = 'uniform'))

model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

from keras.callbacks import EarlyStopping
early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

history = model.fit(x_train, y_train, epochs=35, batch_size=6, validation_split=0.1, callbacks=[early_stop])

y_pred = model.predict(x_test)

y_pred = (y_pred > 0.35).astype(int)

print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)

print("Confusion Matrix:")
print(cm)

len(y_test), len(pred)

saved_model = model.save("diabetes_ann_model.keras")

import pickle

# Save the fitted scaler
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)